# You can use this section to suppress warnings generated by your code:
def warn(*args, **kwargs):
    pass
import warnings
warnings.warn = warn
warnings.filterwarnings('ignore')

from langchain.document_loaders import TextLoader, PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
import os
import glob

from ibm_watsonx_ai.foundation_models import Model
from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams
from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes, DecodingMethods
from ibm_watson_machine_learning.foundation_models.extensions.langchain import WatsonxLLM
import wget

filename = 'p1.pdf'
url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/6JDbUb_L3egv_eOkouY71A.txt'

# Use wget to download the file
# wget.download(url, out=filename)
# print('file downloaded')

# Function to load documents from multiple sources
def load_documents():
    """Load documents from PDF and text files in the current directory"""
    all_documents = []
    
    # Load PDF files
    pdf_files = glob.glob("*.pdf")
    for pdf_file in pdf_files:
        print(f"Loading PDF: {pdf_file}")
        try:
            loader = PyPDFLoader(pdf_file)
            documents = loader.load()
            all_documents.extend(documents)
            print(f"Loaded {len(documents)} pages from {pdf_file}")
        except Exception as e:
            print(f"Error loading {pdf_file}: {e}")
    
    # Load text files (company policies)
    text_files = glob.glob("companyPolicies*.txt")
    for text_file in text_files:
        print(f"Loading text file: {text_file}")
        try:
            loader = TextLoader(text_file)
            documents = loader.load()
            all_documents.extend(documents)
            print(f"Loaded {len(documents)} documents from {text_file}")
        except Exception as e:
            print(f"Error loading {text_file}: {e}")
    
    return all_documents

# Load all documents
print("Loading documents...")
documents = load_documents()
print(f"Total documents loaded: {len(documents)}")

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
texts = text_splitter.split_documents(documents)
print(f"Total text chunks created: {len(texts)}")

embeddings = HuggingFaceEmbeddings()
docsearch = Chroma.from_documents(texts, embeddings)  # store the embedding in docsearch using Chromadb
print('document ingested')

model_id = 'google/flan-t5-xl'

parameters = {
    GenParams.DECODING_METHOD: DecodingMethods.SAMPLE,  
    GenParams.MIN_NEW_TOKENS: 10, # this controls the minimum number of tokens in the generated output
    GenParams.MAX_NEW_TOKENS: 200,  # this controls the maximum number of tokens in the generated output
    GenParams.TEMPERATURE: 0.3, # this randomness or creativity of the model's responses
    GenParams.TOP_P: 0.9,
    GenParams.TOP_K: 50
}

credentials = {
    "url": "https://eu-de.ml.cloud.ibm.com",
    "apikey": "kyFq8XEA_K50zeRSFQLqxZ9QiNQucONQmCCe_FZldpDj"
    # uncomment above when running locally
}

project_id = "8de58445-d17f-414f-8acf-5e2225192984"

model = Model(
    model_id=model_id,
    params=parameters,
    credentials=credentials,
    project_id=project_id
)

flan_ul2_llm = WatsonxLLM(model=model)

# Create a better prompt template
prompt_template = """Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Provide a clear, concise, and helpful answer.

Context: {context}

Question: {question}

Answer:"""

PROMPT = PromptTemplate(
    template=prompt_template, input_variables=["context", "question"]
)

qa = RetrievalQA.from_chain_type(llm=flan_ul2_llm, 
                                 chain_type="stuff", 
                                 retriever=docsearch.as_retriever(search_kwargs={"k": 3}), 
                                 return_source_documents=False,
                                 chain_type_kwargs={"prompt": PROMPT})

# Test with a better question
query = "Can you summarize the key points of our company policies?"
result = qa.invoke(query)
print("Query:", query)
print("Answer:", result)