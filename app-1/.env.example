# Flask Configuration
FLASK_ENV=development
FLASK_DEBUG=False

# Database
DATABASE_URL=sqlite:///app.db

# File Upload
MAX_FILE_SIZE=52428800
UPLOAD_FOLDER=uploads

# Vector Store
VECTOR_DB_PATH=./vector_db
EMBEDDING_MODEL=all-MiniLM-L6-v2

# ============================================================================
# LLM Provider Configuration
# ============================================================================
# 
# LLM_PROVIDER can be: 'openai', 'ibm', or auto-detect from available credentials
# If not set, will auto-detect based on which credentials are available
#
LLM_PROVIDER=openai

# --- OpenAI Configuration (used if LLM_PROVIDER=openai or auto-detected) ---
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_TEMPERATURE=0.7

# --- IBM Watson / WatsonX Configuration (used if LLM_PROVIDER=ibm or auto-detected) ---
# 
# Get these credentials from IBM Cloud:
# 1. IBM_API_KEY: Your IBM Cloud API key (from IBM Cloud console)
# 2. IBM_PROJECT_ID: Your WatsonX project ID
# 3. IBM_URL: WatsonX API URL (region-specific)
#
# Available models:
#   - ibm/granite-3-3-8b-instruct (recommended)
#   - ibm/granite-3-8b-instruct
#   - ibm/llama-2-70b-chat
#   - ibm/mistral-7b-instruct
#
IBM_API_KEY=your-ibm-api-key-here
IBM_PROJECT_ID=your-project-id-here
IBM_URL=https://api.us-south.ml.cloud.ibm.com
IBM_MODEL=ibm/granite-3-3-8b-instruct
IBM_TEMPERATURE=0.5

# ============================================================================
# Usage Notes:
# ============================================================================
# 
# 1. Auto-detection (LLM_PROVIDER not set or empty):
#    - If IBM_API_KEY + IBM_PROJECT_ID are set -> uses IBM Watson
#    - Else if OPENAI_API_KEY is set -> uses OpenAI
#    - Else -> fallback mode (no LLM, returns document context only)
#
# 2. Explicit provider selection:
#    - Set LLM_PROVIDER=openai to force OpenAI
#    - Set LLM_PROVIDER=ibm to force IBM Watson
#
# 3. Fallback mode:
#    - If no LLM is configured/available, the app still works
#    - /api/chat endpoint returns retrieved documents without LLM processing
#
